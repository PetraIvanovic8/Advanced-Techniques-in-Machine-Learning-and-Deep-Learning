# Advanced Techniques in ML and Deep Learning

This repository is a detailed documentation of the most relevant work done in an  NYU Data Science course called ‘"Advanced Topics in Data Science: Advanced Techniques in ML and Deep Learning’. This course provided me with a comprehensive exploration into cutting-edge techniques in machine learning (ML) and deep learning (DL), from model development to post-deployment.<br>

The aim of this course was to gain an understanding of different theoretical concepts that we then applied to extensive hands-on assignments. This allowed me to master the implementation of advanced ML techniques and deepen my theoretical understanding of their underlying principles.

## Concepts and Technologies learned and utilized throughout the course:
- **Comprehensive ML Lifecycle Understanding:** from hyperparameter optimization, feature engineering, to neural architecture search, this course covered the entire spectrum of model development and optimization techniques.
- **Hands-On Experience with Advanced ML Tools:** I gained practical experience with automated ML tools such as Auto-sklearn, Auto-WEKA, and H2O.ai, enhancing my skills in applying these tools for efficient model development.
- **Deep Dive into Deep Learning:** This course provided me with in-depth knowledge on designing and training neural networks using popular frameworks like TensorFlow and PyTorch, covering special architectures like Convolutional Neural Networks (CNNs) for image analysis, Recurrent Neural Networks (RNNs) for sequence data, and Generative Adversarial Networks (GANs) for generating new data instances. Additionally, we tackled Transformer models, fundamental in natural language processing tasks. 
- **Robust and Distributed ML Models:** I also learned about creating robust models through adversarial training, understanding and mitigating model drift, and implementing distributed training and federated learning techniques for scalable ML solutions.
- **Ethical AI:** The course also emphasized the importance of model interpretability and ethical AI, teaching us techniques to make machine learning models more transparent and accountable. <br>
 
Additionally this course also included many labs and assignments as well as a comprehensive project that allowed me to practice and showcase my ability to apply advanced ML and DL techniques to real-world data sets and challenges.

## Contents of This Repository

This repository contains the assignments that covered the wide range of topics taught in the course where we applied the previously mentioned concepts to diverse scenarios and problems. Each folder within the repository is dedicated to a specific assignment and contains detailed documentation, code, and analysis.
Each folder contains the assignment instructions in pdf, and all answers in separate Jupyter Notebooks (.ipynb) as well as supplemental readings (if applicable) and corresponding data (in cases where it was not too large to attach). 

### [Final Project](https://github.com/anastasia-s02/QA-system-for-MCQ)
During the second part of the course the focus was on developing group projects of interest. My group developed an "Efficient Grounded QA System for Multiple Choice Questions". Our model leverages InfoNCE loss, significantly improving the model's ability to distinguish between correct and incorrect answers. The model was designed to accurately identify the correct option from multiple choices based on the given context and question. Additionally, our system also pinpoints the corroborating sentence leading to its decision, enhancing interpretability. This project emphasizes creating an accurate and interpretable model for answering multiple-choice questions, supported by technologies such as Python, Transformers, and Torch. The project and its detailed documentation, including data transformation techniques, model testing, and evaluation, are available in [this](https://github.com/anastasia-s02/QA-system-for-MCQ) repository.

### [Assignment 1](https://github.com/PetraIvanovic8/Advanced-Techniques-in-Machine-Learning-and-Deep-Learning/tree/2978ca6e00c5d66b61f7a2dfcdfcd1f7fab900ea/Assignment%201)
This assignment delved into advanced data science concepts including bias-variance tradeoff, KNN hyperparameter tuning using cross-validation, algorithm comparison for document retrieval, and logistic regression with regularization. Techniques I used involved generating and analyzing datasets to understand bias and variance, utilizing sklearn for KNN with varied hyperparameters, creating confusion matrices and evaluating algorithms based on precision, recall, and F1 scores, and leveraging sklearn's logistic regression with L1 and L2 penalties to examine the impact of regularization on model performance. This comprehensive assignment provided hands-on experience with Python and sklearn, demonstrating the practical application and deep understanding of key machine learning concepts.

### [Assignment 2](https://github.com/PetraIvanovic8/Advanced-Techniques-in-Machine-Learning-and-Deep-Learning/tree/2978ca6e00c5d66b61f7a2dfcdfcd1f7fab900ea/Assignment%202)
This assignment examined algorithmic performance scaling and the precision-recall-ROC relationship using datasets from OpenML and theoretical insights from a key paper. Techniques I used included data summarization, training set subsampling for Decision Tree and Gradient Boosting classifiers, learning curve generation, and training time analysis. Further, the assignment explored Perceptron algorithm implementation, comparing perceptron criterion and hinge-loss, and analyzed linear separability in datasets, introducing concepts of linear classifiers and nonlinear transformations. To solve this assignment I used Python, sklearn, and custom algorithm implementation, demonstrating practical machine learning application and theoretical analysis skills.

### [Assignment 3](https://github.com/PetraIvanovic8/Advanced-Techniques-in-Machine-Learning-and-Deep-Learning/tree/2978ca6e00c5d66b61f7a2dfcdfcd1f7fab900ea/Assignment%203)
This assignment delved into advanced neural network concepts, including softmax activation, backpropagation enhancements, weight initialization effects, dead neurons, and regularization techniques using dropout and batch normalization. Techniques I used involved mathematical derivations for softmax gradients, modifications to neural network architectures for improved learning, experimentation with weight initialization to mitigate vanishing and exploding gradients, and the practical application of Leaky ReLU to prevent dead neurons. The assignment also compared regularization methods on the MNIST dataset, emphasizing hands-on implementation and theoretical understanding of deep learning principles.

### [Assignment 4](https://github.com/PetraIvanovic8/Advanced-Techniques-in-Machine-Learning-and-Deep-Learning/tree/2978ca6e00c5d66b61f7a2dfcdfcd1f7fab900ea/Assignment%204)
This assignment engaged in a detailed exploration of various convolutional neural network (CNN) architectures, transfer learning strategies, weakly and semi-supervised learning for image classification, and Siamese networks for face recognition. Techniques I used involved calculating the number of parameters in networks like AlexNet and VGG, understanding inception modules, applying ResNet50 for transfer learning with fine-tuning and feature extraction, and evaluating Siamese networks with different loss functions. I utilized PyTorch for implementing neural networks, focusing on practical applications in image classification and face recognition.

### [Assignment 5](https://github.com/PetraIvanovic8/Advanced-Techniques-in-Machine-Learning-and-Deep-Learning/tree/2978ca6e00c5d66b61f7a2dfcdfcd1f7fab900ea/Assignment%205)
This assignment covered sentiment analysis with recurrent models, building a simple chatbot using a seq-to-seq model, understanding attention in transformers, and utilizing BERT for question answering. Techniques I utilized involved applying RNN, LSTM, GRU, and BiLSTM models for sentiment analysis on the IMDB dataset, implementing a seq-to-seq model with Luong attention for a chatbot, exploring the mechanism of attention in transformers, and leveraging BERT for sophisticated question answering tasks. This assignment provided hands-on experience with deep learning frameworks like PyTorch, showcasing the practical application of state-of-the-art NLP techniques.

### [Assignment 6](https://github.com/PetraIvanovic8/Advanced-Techniques-in-Machine-Learning-and-Deep-Learning/tree/2978ca6e00c5d66b61f7a2dfcdfcd1f7fab900ea/Assignment%206)
This assignment focused on hyperparameter optimization with H2O, automated feature engineering with AutoFeat, and hyperparameter tuning using Ray Tune for deep learning. Techniques included grid search, randomized grid search, and AutoML for identifying optimal model configurations, as well as AutoFeat for automatic feature engineering and selection. Additionally, the assignment explored Ray Tune's capabilities for hyperparameter optimization using Grid Search, Bayesian Search, and Hyperband, focusing on a deep learning model for the MNIST dataset. The tasks provided hands-on experience with cutting-edge machine learning optimization and feature engineering techniques, showcasing the practical application of these methods in improving model performance and efficiency.

### [Assignment 7](https://github.com/PetraIvanovic8/Advanced-Techniques-in-Machine-Learning-and-Deep-Learning/tree/2978ca6e00c5d66b61f7a2dfcdfcd1f7fab900ea/Assignment%207)
This final assignment tackled asynchronous SGD staleness, data parallelism in PyTorch, SSD model inferencing with ONNX, deep reinforcement learning concepts, and an analysis of ML cloud platforms. It involved theoretical analysis and practical implementation, including calculating gradient staleness in a distributed training setup, experimenting with PyTorch's DataParallel for synchronous SGD across GPUs, deploying an SSD model for object detection using ONNX, and exploring deep RL algorithms and architectures. Additionally, the assignment included a comparison of ML cloud services from IBM, Google, Microsoft, and Amazon based on various criteria such as supported frameworks, compute units, and model lifecycle management tools.
