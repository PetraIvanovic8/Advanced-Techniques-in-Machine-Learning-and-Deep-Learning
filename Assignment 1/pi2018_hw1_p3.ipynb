{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcDhlfqyBd6m"
      },
      "source": [
        "# Problem 3 - Which Algorithm is Better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-id00ye6CNLB"
      },
      "source": [
        "## 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kineJbrfcg7"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "**Confusion Matrix Retrieval Algorithm 1:**\n",
        "\n",
        "|   | Actual <br> Positive  | Actual <br> Negative  |\n",
        "|:---:|:---:|:---:|\n",
        "| **Predicted <br> Positive** | 25 | 15 |\n",
        "| **Predicted <br> Negative** | 5 | 55 |\n",
        "\n",
        "\n",
        "Calculations:\n",
        "\n",
        "True Positive = number of values that were positive (relevant) in the algorithm 1 and were also positive in reference = 25\n",
        "\n",
        "False Positive = number of values that were positive (relevant) in the algorithm 1 and but were actually negative (irrelevant) in reference = 15\n",
        "\n",
        "True Negative = number of values that were negative (irrelevant) in the algorithm 1 and were also negative in reference = 55\n",
        "\n",
        "False Negative = number of values that were negative (irrelevant) in the algorithm 1 and but were actually positive (relevant) in reference = 5\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Confusion Matrix Retrieval Algorithm 2:**\n",
        "\n",
        "|   | Actual <br> Positive  | Actual <br> Negative  |\n",
        "|:---:|:---:|:---:|\n",
        "| **Predicted <br> Positive** | 20 | 10 |\n",
        "| **Predicted <br> Negative** | 10 | 60 |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Calculations:\n",
        "\n",
        "True Positive = number of values that were positive (relevant) in the algorithm 2 and were also positive in reference = 20\n",
        "\n",
        "False Positive = number of values that were positive (relevant) in the algorithm 2 and but were actually negative (irrelevant) in reference = 10\n",
        "\n",
        "True Negative = number of values that were negative (irrelevant) in the algorithm 2 and were also negative in reference = 60\n",
        "\n",
        "False Negative = number of values that were negative (irrelevant) in the algorithm 2 and but were actually positive (relevant) in reference = 10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1D_yfneCWqL"
      },
      "source": [
        "## 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX8Ns_Imf-BI"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "Balanced Accuracy is a metric that takes into account both sensitivity, \"True Positive Rate\", and specificity, \"True Negative Rate\", and is useful when dealing with imbalanced datasets. Due to this, Balanced Accuracy is used in btoh binary and multi-calss classification and is useful when dealing with imbalanced data.\n",
        "\n",
        "\n",
        "\n",
        "F-1 Score is a harmonic mean of precision and recall and is particularly useful when you want to balance between false positives and false negatives. The F-1 Score metric calculates how many times a model has made a correct prediction across the entire dataset.\n",
        "\n",
        "\n",
        "\n",
        "Lets calculate Balanced Accuracy and F-1 Scores for both algorithms and see how they perform:\n",
        "\n",
        "**Balanced Accuracy:**\n",
        "\n",
        "For Algorithm 1:\n",
        "\n",
        "$\\begin{align}\n",
        "  Sensitivity &= \\frac{TP}{(TP+FN)}=\\frac{25}{(25+5)}=0.8333\\\\\n",
        "  Specificity &= \\frac{TN}{(TN+FP)}=\\frac{55}{(55+15)}=0.7857\\\\\n",
        "  Balanced Accuracy &= \\frac{(Sensitivity + Specificity)}{2}=0.8095\\\\\n",
        "\\end{align}$\n",
        "\n",
        "\n",
        "\n",
        "For Algorithm 2:\n",
        "\n",
        "$\\begin{align}\n",
        "  Sensitivity &= \\frac{TP}{(TP+FN)}=\\frac{20}{(20+10)}=0.6667\\\\\n",
        "  Specificity &= \\frac{TN}{(TN+FP)}=\\frac{60}{(60+10)}=0.8571\\\\\n",
        "  Balanced Accuracy &= \\frac{(Sensitivity + Specificity)}{2}=0.7619\\\\\n",
        "\\end{align}$\n",
        "\n",
        "\n",
        "\n",
        "Looking at these calculations for Balanced Accuracy we can say that the Algorithm 1 is the better model since it has larger accuracy at 0.8095.\n",
        "\n",
        "\n",
        "\n",
        "**F-1 Score:**\n",
        "\n",
        "\n",
        "For Algorithm 1:\n",
        "\n",
        "$\\begin{align}\n",
        "  Precision &= \\frac{TP}{(TP+FP)}=\\frac{25}{(25+15)}=0.625\\\\\n",
        "  Recall &= \\frac{TP}{(TP+FN)}=\\frac{25}{(25+5)}=0.8333\\\\\n",
        "  F-1 Score &= 2 × \\frac{(Precision × Recall)}{(Precision + Recall)}=0.7143\\\\\n",
        "\\end{align}$\n",
        "\n",
        "\n",
        "\n",
        "For Algorithm 2:\n",
        "\n",
        "$\\begin{align}\n",
        "  Precision &= \\frac{TP}{(TP+FP)}=\\frac{20}{(20+10)}=0.6667\\\\\n",
        "  Recall &= \\frac{TP}{(TP+FN)}=\\frac{20}{(20+10)}=0.6667\\\\\n",
        "  F-1 Score &= 2 × \\frac{(Precision × Recall)}{(Precision + Recall)}=0.6667\\\\\n",
        "\\end{align}$\n",
        "\n",
        "\n",
        "\n",
        "Looking at these calculations for F-1 Score we can also say that the Algorithm 1 is the better model since it has larger F-1 Score at 0.7143.\n",
        "\n",
        "\n",
        "\n",
        "I belive that neither party was wrong in their recommendations and both measures are valuable in seeing which algorithm might be better for our specific case. And that has also been suppored by the fact that they both identified the same algorithm as better. Balanced Accuracy is a good measurement to use in our case due to the fact our reference has significantly more negative casses compared to positive and it also takes into consideration Specificity, or True Negative rate which is useful since we are interested in finding the algorithm tht has better performance on negative classes. Further, F-1 Score is a good metric since it provides a balance between false positives and false negatives and is usefull when we want to minimize false negatives and false positives.\n",
        "\n",
        "\n",
        "\n",
        "While F-1 Score might be more appropriate in our case since we are looking for an algorithm with better perfomance on negative cases, I belive both are valuable measures that can give us a lot of insight.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpMHZDOECjD3"
      },
      "source": [
        "## 3.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRo9fm0tf-ga"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "The advice of the friend and the instructor helped me identify Algorithm 1 as the algorithm that has better performance on negative classes. It is worth to note that while Algorithm 1 is performing slightly better, both algorithms have very similar perfomrance metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdDLYruzClXn"
      },
      "source": [
        "## 3.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdaMp6ZBf_DF"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "Metrics that had most value in making the decision were F-1 Score, Specificity (True Negative Rate), and Balanced Accuracy. Other metrics that are worth to note in this specific case are Precision and Negative Predicted Value which is a proportion of true negatives among all the instances predicted as negative which is also higher for Algorithm 1 again noting it as more appropriate.\n",
        "\n",
        "\n",
        "\n",
        "**Calculation of Negative Predicted Value:**\n",
        "\n",
        "\n",
        "**Algorithm 1:**\n",
        "\n",
        "Negative Predicted Value = \\frac{TN}{TN+FN} = \\frac{55}{55+5} = 0.9167\n",
        "\n",
        "\n",
        "**Algorithm 2:**\n",
        "\n",
        "Negative Predicted Value = \\frac{TN}{TN+FN} = \\frac{60}{60+10} = 0.8571"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kuPBwGC8T8I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
